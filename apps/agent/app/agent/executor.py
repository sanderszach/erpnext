"""
Executor node for the agent graph.

This module contains the executor node which takes a plan
and executes it (potentially using tools).
"""

from app.agent.state import AgentState
from app.config import settings


async def executor_node(state: AgentState) -> AgentState:
    """
    Execute the plan generated by the planner.

    This node takes the plan from the state and executes it.
    Currently uses mock logic - replace with actual tool execution when ready.

    Args:
        state: The current agent state containing the plan.

    Returns:
        Updated state with the execution output.
    """
    plan = state.get("plan", "")
    user_input = state.get("input", "")

    # TODO: Replace with actual execution logic
    # This is where you would:
    # 1. Parse the plan
    # 2. Invoke appropriate tools
    # 3. Handle tool results
    # 4. Generate final response
    #
    # Example with LangChain tools:
    #
    # from app.tools import get_available_tools
    # from langchain_openai import ChatOpenAI
    #
    # llm = ChatOpenAI(model=settings.llm_model)
    # tools = get_available_tools()
    # llm_with_tools = llm.bind_tools(tools)
    #
    # # Execute based on plan...

    # Mock execution logic for demonstration
    output = f"Executed plan for: '{user_input}'\n\nResult: This is a mock response. Replace with actual tool execution."

    # Log the execution step (in production, use proper logging)
    if settings.app_env == "development":
        print(f"[Executor] Executed plan: {plan[:50]}...")

    return {
        **state,
        "output": output,
        "metadata": {
            **state.get("metadata", {}),
            "executor": {
                "tools_used": [],  # Populate when tools are actually used
                "model": settings.llm_model,
            },
        },
    }

